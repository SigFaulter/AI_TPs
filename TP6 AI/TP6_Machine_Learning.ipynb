{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBY1Vdsp00eN"
      },
      "source": [
        "<center><h1> Corréction Série de Travaux Pratiques N° 6 - Machine Learning </h1></center>\n",
        "<center><h2> Regression Logistique</h2></center>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xIqBKf-_MK9"
      },
      "source": [
        "# **Partie I : Regression Logistique**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OT_v-xSH8NW"
      },
      "source": [
        "Vous trouverez ci-joint un exemple d'utilisation d'algorithme de regréssion logistique avec les quatres étapes principales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JhmrQYpLAkeD",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Step 1: Import packages, functions\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Step 2: Get data\n",
        "x = np.arange(10).reshape(-1, 1)\n",
        "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "# Step 3: Create a model and train it\n",
        "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0, max_iter=100)\n",
        "model.fit(x, y)\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "p_pred = model.predict_proba(x)\n",
        "y_pred = model.predict(x)\n",
        "score_ = model.score(x, y)\n",
        "conf_m = confusion_matrix(y, y_pred)\n",
        "report = classification_report(y, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl6j49CVBPZy",
        "metadata": {},
        "outputId": "1fbd1535-bc83-4900-ad7d-5282b5b93143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: [[0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]\n",
            " [9]]\n",
            "y: [0 1 0 0 1 1 1 1 1 1]\n",
            "intercept: [-1.51632619]\n",
            "coef: [[0.703457]]\n",
            "p_pred: [[0.81999686 0.18000314]\n",
            " [0.69272057 0.30727943]\n",
            " [0.52732579 0.47267421]\n",
            " [0.35570732 0.64429268]\n",
            " [0.21458576 0.78541424]\n",
            " [0.11910229 0.88089771]\n",
            " [0.06271329 0.93728671]\n",
            " [0.03205032 0.96794968]\n",
            " [0.0161218  0.9838782 ]\n",
            " [0.00804372 0.99195628]]\n",
            "y_pred: [0 0 0 1 1 1 1 1 1 1]\n",
            "score_: 0.8\n",
            "conf_m: [[2 1]\n",
            " [1 6]]\n",
            "report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67         3\n",
            "           1       0.86      0.86      0.86         7\n",
            "\n",
            "    accuracy                           0.80        10\n",
            "   macro avg       0.76      0.76      0.76        10\n",
            "weighted avg       0.80      0.80      0.80        10\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('x:', x)\n",
        "print('y:', y)\n",
        "print('intercept:', model.intercept_)\n",
        "print('coef:', model.coef_)\n",
        "print('p_pred:', p_pred)\n",
        "print('y_pred:', y_pred)\n",
        "print('score_:', score_)\n",
        "print('conf_m:', conf_m)\n",
        "print('report:', report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CRPgzmJAP9p"
      },
      "source": [
        "# **Partie II : Classification Binaire**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifx0Fkf3QfMe"
      },
      "source": [
        "L'objectif de l'ensemble de données \"**diabetes.csv**\" est de prédire, sur la base de mesures diagnostiques, si un patient **souffre de diabète ou pas**.\n",
        "\n",
        "Ce dataset contient les caractéristiques suivants\n",
        "\n",
        "**Grossesses**: Nombre de fois enceintes.\n",
        "\n",
        "**Glucose**: concentration plasmatique de glucose à 2 heures lors d'un test oral de tolérance au glucose.\n",
        "\n",
        "**Pression artérielle** : tension artérielle diastolique (mm Hg).\n",
        "\n",
        "**Épaisseur de la peau** : épaisseur du pli cutané du triceps (mm).\n",
        "\n",
        "**Insuline** : insuline sérique de 2 heures (mu U/ml).\n",
        "\n",
        "**IMC** : Indice de masse corporelle (poids en kg/(taille en m)^2).\n",
        "\n",
        "**DiabetesPedigreeFunction** : fonction généalogique du diabète.\n",
        "\n",
        "**Âge** : Âge (ans).\n",
        "\n",
        "**Résultat** : variable de classe (0 ou 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFizXutMLhX1"
      },
      "source": [
        "### **Questions :**\n",
        "\n",
        "Étape 1 : Importer et afficher et explorer l'ensemble de données \"**diabetes.csv**\"\n",
        "\n",
        "Étape 2 : Créer dépendante d'une variable indépendante et stockée sur les variables X et Y.\n",
        "\n",
        "Étape 3 : Transformer les chaînes en entier.\n",
        "\n",
        "Étape 4 : Divisez les données en ensembles d'entrainement et de test.\n",
        "\n",
        "Étape 5 : Définir l'algorithme de régression logistique.\n",
        "\n",
        "Étape 6 :Tester les données de test en utilisant votre modèle.\n",
        "\n",
        "Étape 7 : Évaluation du modèle.\n",
        "\n",
        "Étape 8 : Prédire avec de nouvelles valeurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wlRBxy0D99y",
        "metadata": {},
        "outputId": "cefe284a-c332-46d5-8dd8-cb6ab624d608"
      },
      "outputs": [],
      "source": [
        "# # Se connecter\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "dataset = read_csv(\"diabetes.csv\")\n",
        "dataset.head()\n",
        "x = dataset[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
        "# x = dataset.drop(\"Outcome\", axis=1)\n",
        "y = dataset['Outcome']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0NC3rVjEMTt",
        "metadata": {},
        "outputId": "c99b0f4b-e00b-4002-b048-7794de9c3307"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [768, 254]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[43], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m      7\u001b[0m x_encoded \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mapply(label_encoder\u001b[38;5;241m.\u001b[39mfit_transform)\n\u001b[0;32m----> 8\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.33\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape())\n",
            "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
            "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2657\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2662\u001b[0m )\n",
            "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/utils/validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [768, 254]"
          ]
        }
      ],
      "source": [
        "# cd drive/My Drive/Colab Notebooks\n",
        "\n",
        "# Notes:\n",
        "# Precesion = VP/(VP+FP) -> Dans tous les cas positives, combien son reelement positive\n",
        "# Recall = VP/(VP+FN) -> Dans tous les cas reelement positives, combien le model a predire correctement\n",
        "label_encoder = LabelEncoder()\n",
        "x_encoded = x.apply(label_encoder.fit_transform)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_encoded, y, test_size=0.33)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_NuxG5qDTWyp",
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8188976377952756"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Binary Classification : Diabetes\n",
        "lr_model.predict(x_test)\n",
        "lr_model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Zbjz_AAZ5l"
      },
      "source": [
        "# **Partie II : Classification Multi-Classe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1NijNx4OpVg"
      },
      "source": [
        "Pour cette partie, on utilisera le **dataset IRIS**. Ce dernier est une base de données regroupant les caractéristiques de **trois espèces de fleurs d’Iris, à savoir Setosa, Versicolour et Virginica**. Chaque ligne de ce jeu de données est une observation des caractéristiques d’une fleur d’Iris. Ce dataset décrit les espèces d’Iris par quatre propriétés : longueur et largeur de sépales ainsi que longueur et largeur de pétales. La base de données comporte 150 observations (50 observations par espèce)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSTbiW8UMiPt"
      },
      "source": [
        "### **Questions :**\n",
        "\n",
        "Étape 1 : Importer, afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
        "\n",
        "Étape 2 : Créer dépendante d'une variable indépendante et stockée sur les variables X et Y.\n",
        "\n",
        "Étape 3 : Transformer les chaînes en entier.\n",
        "\n",
        "Étape 4 : Divisez les données en ensembles d'entrainement et de test.\n",
        "\n",
        "Étape 5 : Définir l'algorithme de régression logistique.\n",
        "\n",
        "Étape 6 :Tester les données de test en utilisant votre modèle.\n",
        "\n",
        "Étape 7 : Évaluation du modèle.\n",
        "\n",
        "Étape 8 : Prédire avec de nouvelles valeurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P8PUWA4oTlBB",
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sepal.length  sepal.width  petal.length  petal.width variety\n",
            "0           5.1          3.5           1.4          0.2  Setosa\n",
            "1           4.9          3.0           1.4          0.2  Setosa\n",
            "2           4.7          3.2           1.3          0.2  Setosa\n",
            "3           4.6          3.1           1.5          0.2  Setosa\n",
            "4           5.0          3.6           1.4          0.2  Setosa\n",
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Setosa       1.00      1.00      1.00        10\n",
            "  Versicolor       1.00      1.00      1.00         9\n",
            "   Virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "New Predictions: ['Setosa' 'Versicolor']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Multi-Class Classification : IRIS Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier CSV\n",
        "df = pd.read_csv('iris.csv')\n",
        "\n",
        "# Afficher les premières lignes pour explorer les données\n",
        "print(df.head())\n",
        "\n",
        "# Définir les variables indépendantes (features) et la variable dépendante (target)\n",
        "X = df[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']]\n",
        "Y = df['variety']\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encoder les étiquettes de la colonne 'variety'\n",
        "label_encoder = LabelEncoder()\n",
        "Y_encoded = label_encoder.fit_transform(Y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement et de test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instancier le modèle de régression logistique\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Former le modèle sur les données d'entraînement\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Prédire les étiquettes pour les données de test\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Calculer l'accuracy\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Afficher la matrice de confusion\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Afficher le rapport de classification\n",
        "class_report = classification_report(Y_test, Y_pred, target_names=label_encoder.classes_)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Exemple de nouvelles valeurs pour prédiction\n",
        "new_values = [[5.1, 3.5, 1.4, 0.2], [6.7, 3.1, 4.4, 1.4]]\n",
        "\n",
        "# Prédire les classes des nouvelles valeurs\n",
        "new_predictions = model.predict(new_values)\n",
        "\n",
        "# Convertir les prédictions en noms de classes\n",
        "new_predictions_labels = label_encoder.inverse_transform(new_predictions)\n",
        "print(\"New Predictions:\", new_predictions_labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
