{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBY1Vdsp00eN"
      },
      "source": [
        "<center><h1> Série de Travaux Pratiques N° 7 - Machine Learning </h1></center>\n",
        "<center><h2> K-Nearest Neighbor and Decision Tree</h2></center>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OT_v-xSH8NW"
      },
      "source": [
        "Pour ce TP, on utilisera le **dataset IRIS**. Ce dernier est une base de données regroupant les caractéristiques de **trois espèces de fleurs d’Iris, à savoir Setosa, Versicolour et Virginica**. Chaque ligne de ce jeu de données est une observation des caractéristiques d’une fleur d’Iris. Ce dataset décrit les espèces d’Iris par quatre propriétés : longueur et largeur de sépales ainsi que longueur et largeur de pétales. La base de données comporte 150 observations (50 observations par espèce)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xIqBKf-_MK9"
      },
      "source": [
        "# **Partie I : K-Nearest Neighbor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG-mqDhouw_G"
      },
      "source": [
        "# **Questions :**\n",
        "\n",
        "1- Importer les packages nécessaires\n",
        "\n",
        "2- Lire l'ensemble de données dans le dataframe pandas\n",
        "\n",
        "3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
        "\n",
        "4- Extraire les variables d'entrée X\n",
        "\n",
        "5- Extraire les variables de sortie y\n",
        "\n",
        "6- Diviser le dataset en Train / Test\n",
        "\n",
        "7- Mise à l'échelle des fonctionnalités avec Transform()\n",
        "\n",
        "8- Définir votre modèle **KNN**\n",
        "\n",
        "9- Entraîner le modèle\n",
        "\n",
        "10- Prédiction sur l'ensemble de test\n",
        "\n",
        "11- Évaluation du modèle à l'aide de métriques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ab1P8GZVw4gj",
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sepal.length  sepal.width  petal.length  petal.width variety\n",
            "0           5.1          3.5           1.4          0.2  Setosa\n",
            "1           4.9          3.0           1.4          0.2  Setosa\n",
            "2           4.7          3.2           1.3          0.2  Setosa\n",
            "3           4.6          3.1           1.5          0.2  Setosa\n",
            "4           5.0          3.6           1.4          0.2  Setosa\n",
            "\n",
            "Accuracy: 0.94\n",
            "\n",
            "K = 5 -> Accuracy == 0.94\n",
            "K = 10 -> Accuracy == 0.92\n",
            "K = 20 -> Accuracy == 0.92\n",
            "K = 30 -> Accuracy == 0.88\n",
            "K = 40 -> Accuracy == 0.82\n"
          ]
        }
      ],
      "source": [
        "# IRIS Dataset : KNN\n",
        "\n",
        "# 1- Importer les packages nécessaires\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 2- Lire l'ensemble de données dans le dataframe pandas\n",
        "df = pd.read_csv(\"iris.csv\")\n",
        "\n",
        "# 3- Afficher et explorer l'ensemble de données \"iris.csv\"\n",
        "print(df.head())\n",
        "\n",
        "# 4- Extraire les variables d'entrée X\n",
        "x = df.drop(\"variety\", axis=1)\n",
        "\n",
        "# 5- Extraire les variables de sortie y\n",
        "y = df['variety']\n",
        "\n",
        "# 6- Diviser le dataset en Train / Test\n",
        "label_encoder = LabelEncoder()\n",
        "x_encoded = x.apply(label_encoder.fit_transform)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_encoded, y, test_size=0.33)\n",
        "\n",
        "# 7- Mise à l'échelle des fonctionnalités avec StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# 8- Définir votre modèle KNN\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# 9- Entraîner le modèle\n",
        "knn.fit(x_train_scaled, y_train)\n",
        "\n",
        "# 10- Prédiction sur l'ensemble de test\n",
        "y_pred = knn.predict(x_test_scaled)\n",
        "\n",
        "# 11- Évaluation du modèle à l'aide de métriques\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy}\\n\")\n",
        "\n",
        "# 12- Changer le K = {5, 10, 20, 30, 40}, que remarquez-vous?\n",
        "k_values = [5, 10, 20, 30, 40]\n",
        "\n",
        "# Accuracy changes with the same values between different executions\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(x_train_scaled, y_train)\n",
        "    y_pred = knn.predict(x_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"K = {k} -> Accuracy == {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRAn-qhBwqgp"
      },
      "source": [
        "# **Partie II : Decision Trees**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU1ELn91wg2R"
      },
      "source": [
        "# **Questions :**\n",
        "\n",
        "1- Importer les packages nécessaires\n",
        "\n",
        "2- Lire l'ensemble de données dans le dataframe pandas\n",
        "\n",
        "3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
        "\n",
        "4- Extraire les variables d'entrée X\n",
        "\n",
        "5- Extraire les variables de sortie y\n",
        "\n",
        "6- Diviser le dataset en Train / Test\n",
        "\n",
        "7- Mise à l'échelle des fonctionnalités avec Transform()\n",
        "\n",
        "8- Définir votre modèle **Decision Tree**\n",
        "\n",
        "9- Entraîner le modèle\n",
        "\n",
        "10- Prédiction sur l'ensemble de test\n",
        "\n",
        "11- Évaluation du modèle à l'aide de métriques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EfkJv-sMxI-c",
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sepal.length  sepal.width  petal.length  petal.width variety\n",
            "0           5.1          3.5           1.4          0.2  Setosa\n",
            "1           4.9          3.0           1.4          0.2  Setosa\n",
            "2           4.7          3.2           1.3          0.2  Setosa\n",
            "3           4.6          3.1           1.5          0.2  Setosa\n",
            "4           5.0          3.6           1.4          0.2  Setosa\n",
            "Accuracy: 0.9777777777777777\n",
            "Recall: 0.9777777777777777\n",
            "f1: 0.9777777777777777\n"
          ]
        }
      ],
      "source": [
        "# IRIS Dataset : Decision Tree\n",
        "\n",
        "# 1- Importer les packages nécessaires\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 2- Lire l'ensemble de données dans le dataframe pandas\n",
        "df = pd.read_csv(\"iris.csv\")\n",
        "\n",
        "# 3- Afficher et explorer l'ensemble de données \"iris.csv\"\n",
        "print(df.head())\n",
        "\n",
        "# 4- Extraire les variables d'entrée X\n",
        "x = df.drop(\"variety\", axis=1)\n",
        "\n",
        "# 5- Extraire les variables de sortie y\n",
        "y = df[\"variety\"]\n",
        "\n",
        "# 6- Diviser le dataset en Train / Test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=39)\n",
        "\n",
        "# 7- Mise à l'échelle des fonctionnalités avec StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# 8- Définir votre modèle Decision Tree\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# 9- Entraîner le modèle\n",
        "model.fit(x_train_scaled, y_train)\n",
        "\n",
        "# 10- Prédiction sur l'ensemble de test\n",
        "y_pred = model.predict(x_test_scaled)\n",
        "\n",
        "# 11- Évaluation du modèle à l'aide de métriques\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='micro')\n",
        "f1 = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"f1: {f1}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
